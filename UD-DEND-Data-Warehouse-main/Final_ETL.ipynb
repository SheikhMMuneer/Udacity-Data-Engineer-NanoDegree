{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f8fb7968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::712001213231:role/myRedshiftRole\n"
     ]
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "\n",
    "# CONFIG\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dwh.cfg')\n",
    "\n",
    "# LOAD VARIABLES\n",
    "iam_role      = config.get('IAM_ROLE', 'ARN')\n",
    "log_data      = config.get('S3', 'LOG_DATA')\n",
    "log_json_path = config.get('S3', 'LOG_JSONPATH')\n",
    "song_data     = config.get('S3', 'SONG_DATA')\n",
    "s3_region     = config.get('S3', 'S3_REGION')\n",
    "\n",
    "print(iam_role)\n",
    "\n",
    "# DROP TABLES\n",
    "staging_events_table_drop = \"DROP TABLE IF EXISTS staging_events\"\n",
    "staging_songs_table_drop  = \"DROP TABLE IF EXISTS staging_songs\"\n",
    "songplay_table_drop       = \"DROP TABLE IF EXISTS fact_songplays\"\n",
    "user_table_drop           = \"DROP TABLE IF EXISTS dim_users\"\n",
    "song_table_drop           = \"DROP TABLE IF EXISTS dim_songs\"\n",
    "artist_table_drop         = \"DROP TABLE IF EXISTS dim_artists\"\n",
    "time_table_drop           = \"DROP TABLE IF EXISTS dim_time\"\n",
    "\n",
    "# CREATE TABLES\n",
    "staging_events_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS staging_events (\n",
    "                                  artist          TEXT,\n",
    "                                  auth            TEXT,\n",
    "                                  firstName       TEXT,\n",
    "                                  gender          TEXT,\n",
    "                                  itemInSession   INT,\n",
    "                                  lastName        TEXT,\n",
    "                                  length          TEXT,\n",
    "                                  level           TEXT,\n",
    "                                  location        TEXT,\n",
    "                                  method          TEXT,\n",
    "                                  page            TEXT,\n",
    "                                  registration    TEXT,\n",
    "                                  sessionId       INT,\n",
    "                                  song            TEXT,\n",
    "                                  status          INT,\n",
    "                                  ts              BIGINT,\n",
    "                                  userAgent       TEXT,\n",
    "                                  userId          INT\n",
    "                                  );\n",
    "\"\"\")\n",
    "\n",
    "staging_songs_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS staging_songs (\n",
    "                                 num_songs          INT,\n",
    "                                 artist_id          TEXT,\n",
    "                                 artist_latitude    TEXT,\n",
    "                                 artist_longitude   TEXT,\n",
    "                                 artist_location    TEXT,\n",
    "                                 artist_name        TEXT,\n",
    "                                 song_id            TEXT,\n",
    "                                 title              TEXT,\n",
    "                                 duration           TEXT,\n",
    "                                 year               INT\n",
    "                                 );\n",
    "\"\"\")\n",
    "\n",
    "songplay_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS fact_songplays (\n",
    "                            songplay_id   INT         IDENTITY (0,1)   PRIMARY KEY,\n",
    "                            start_time    TIMESTAMP   NOT NULL         SORTKEY,\n",
    "                            user_id       INT         NOT NULL,\n",
    "                            level         TEXT        NOT NULL,\n",
    "                            song_id       TEXT        NOT NULL         DISTKEY,\n",
    "                            artist_id     TEXT        NOT NULL,\n",
    "                            session_id    INT,       \n",
    "                            location      TEXT,    \n",
    "                            user_agent    TEXT,\n",
    "                            FOREIGN KEY(start_time)   REFERENCES dim_time(start_time),\n",
    "                            FOREIGN KEY(user_id)      REFERENCES dim_users(user_id),\n",
    "                            FOREIGN KEY(song_id)      REFERENCES dim_songs(song_id),\n",
    "                            FOREIGN KEY(artist_id)    REFERENCES dim_artists(artist_id)      \n",
    "                            );\n",
    "                        \n",
    "\"\"\")\n",
    "\n",
    "user_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS dim_users (\n",
    "                        user_id      INT    NOT NULL   PRIMARY KEY,\n",
    "                        first_name   TEXT   NOT NULL,\n",
    "                        last_name    TEXT   NOT NULL,\n",
    "                        gender       TEXT,\n",
    "                        level        TEXT   NOT NULL\n",
    "                        );\n",
    "\"\"\")\n",
    "\n",
    "song_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS dim_songs (\n",
    "                        song_id     TEXT    NOT NULL   PRIMARY KEY   DISTKEY,\n",
    "                        title       TEXT    NOT NULL,\n",
    "                        artist_id   TEXT    NOT NULL,\n",
    "                        year        INT,\n",
    "                        duration    FLOAT,  \n",
    "                        FOREIGN KEY(artist_id) REFERENCES dim_artists(artist_id)\n",
    "                        );\n",
    "\"\"\")\n",
    "\n",
    "artist_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS dim_artists (\n",
    "                          artist_id   TEXT    NOT NULL   PRIMARY KEY,\n",
    "                          name        TEXT    NOT NULL,\n",
    "                          location    TEXT,\n",
    "                          latitude    FLOAT,  \n",
    "                          longitude   FLOAT\n",
    "                          );\n",
    "\"\"\")\n",
    "\n",
    "time_table_create = (\"\"\"CREATE TABLE IF NOT EXISTS dim_time (\n",
    "                        start_time   TIMESTAMP   NOT NULL   PRIMARY KEY   SORTKEY,\n",
    "                        hour         INT         NOT NULL,\n",
    "                        day          INT         NOT NULL,\n",
    "                        week         INT         NOT NULL,\n",
    "                        month        INT         NOT NULL,\n",
    "                        year         INT         NOT NULL,\n",
    "                        weekday      INT         NOT NULL\n",
    "                        );\n",
    "\"\"\")\n",
    "\n",
    "# STAGING TABLES\n",
    "staging_events_copy = (\"\"\"COPY staging_events\n",
    "                          FROM {0}\n",
    "                          IAM_ROLE {1}\n",
    "                          FORMAT JSON AS 'auto'\n",
    "                          REGION {2};\n",
    "\"\"\").format(log_data, iam_role, s3_region)\n",
    "\n",
    "staging_songs_copy = (\"\"\"COPY staging_songs\n",
    "                         FROM {0}\n",
    "                         IAM_ROLE {1}\n",
    "                         FORMAT JSON AS 'auto'\n",
    "                         REGION {2}\n",
    "                         COMPUPDATE OFF;\n",
    "\"\"\").format(song_data, iam_role, s3_region)\n",
    "\n",
    "# FINAL TABLES\n",
    "songplay_table_insert = (\"\"\"INSERT INTO fact_songplays (\n",
    "                            start_time, user_id, level, song_id,\n",
    "                            artist_id, session_id, location, user_agent)\n",
    "                            SELECT TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second',\n",
    "                            e.userId,\n",
    "                            e.level,\n",
    "                            s.song_id,\n",
    "                            s.artist_id,\n",
    "                            e.sessionId,\n",
    "                            e.location,\n",
    "                            e.userAgent\n",
    "                            FROM staging_events AS e\n",
    "                            JOIN staging_songs AS s\n",
    "                            ON e.song=s.title\n",
    "                            AND e.artist=s.artist_name\n",
    "                            WHERE e.page='NextSong';\n",
    "\"\"\")\n",
    "\n",
    "user_table_insert = (\"\"\"INSERT INTO dim_users (\n",
    "                        user_id, first_name, last_name, gender, level)\n",
    "                        SELECT DISTINCT userId,\n",
    "                        firstName,\n",
    "                        lastName,\n",
    "                        gender,\n",
    "                        level\n",
    "                        FROM staging_events\n",
    "                        WHERE page='NextSong';\n",
    "\"\"\")\n",
    "\n",
    "song_table_insert = (\"\"\"INSERT INTO dim_songs (\n",
    "                        song_id, title, artist_id, year, duration)\n",
    "                        SELECT DISTINCT song_id,\n",
    "                        title,\n",
    "                        artist_id,\n",
    "                        year,\n",
    "                        CONVERT(FLOAT, duration)\n",
    "                        FROM staging_songs;\n",
    "\"\"\")\n",
    "\n",
    "artist_table_insert = (\"\"\"INSERT INTO dim_artists (\n",
    "                          artist_id, name, location, latitude, longitude)\n",
    "                          SELECT DISTINCT artist_id,\n",
    "                          artist_name,\n",
    "                          artist_location,\n",
    "                          CONVERT(FLOAT, artist_latitude),\n",
    "                          CONVERT(FLOAT, artist_longitude)\n",
    "                          FROM staging_songs;\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"INSERT INTO dim_time (\n",
    "                        start_time, hour, day, week, month, year, weekday)\n",
    "                        SELECT DISTINCT TIMESTAMP 'epoch' + e.ts/1000 *INTERVAL '1 second' AS dt,\n",
    "                        EXTRACT(hour FROM dt),\n",
    "                        EXTRACT(day FROM dt),\n",
    "                        EXTRACT(week FROM dt),\n",
    "                        EXTRACT(month FROM dt),\n",
    "                        EXTRACT(year FROM dt),\n",
    "                        EXTRACT(dow FROM dt)\n",
    "                        FROM staging_events as e\n",
    "                        WHERE e.page='NextSong';\n",
    "\"\"\")\n",
    "\n",
    "# QUERY LISTS\n",
    "create_table_queries = [staging_events_table_create, staging_songs_table_create, user_table_create, artist_table_create, song_table_create, time_table_create, songplay_table_create]\n",
    "drop_table_queries   = [staging_events_table_drop, staging_songs_table_drop, songplay_table_drop, user_table_drop, song_table_drop, artist_table_drop, time_table_drop]\n",
    "#copy_table_queries  = [staging_events_copy, staging_songs_copy]\n",
    "copy_table_queries   = [staging_songs_copy]\n",
    "insert_table_queries = [songplay_table_insert, user_table_insert, song_table_insert, artist_table_insert, time_table_insert]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68045f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def drop_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Description: This function is used to drop the tables\n",
    "                 defined in the array 'drop_table_queries'\n",
    "    \n",
    "    Arguments:\n",
    "        cur: the cursor object\n",
    "        conn: object of the connection to the database\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for query in drop_table_queries:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def create_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Description: This function is used to create the tables\n",
    "                 defined in the array 'create_table_queries'\n",
    "    \n",
    "    Arguments:\n",
    "        cur: the cursor object\n",
    "        conn: object of the connection to the database\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for query in create_table_queries:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Description: This main function connects to the database and provides the cursor.\n",
    "                 It also triggers dropping and creating of the tables.\n",
    "    \n",
    "    Arguments:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('dwh.cfg')\n",
    "\n",
    "        conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        drop_tables(cur, conn)\n",
    "        create_tables(cur, conn)\n",
    "\n",
    "        conn.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b869be10",
   "metadata": {},
   "outputs": [],
   "source": [
    " main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d5c575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_staging_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Description: This function is used to trigger the extract-process\n",
    "                 of the data from the json-files to the staging tables\n",
    "                 \n",
    "    Arguments:\n",
    "        cur: the cursor object\n",
    "        conn: object of the connection to the database\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for query in copy_table_queries:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def insert_tables(cur, conn):\n",
    "    \"\"\"\n",
    "    Description: This function triggers the transform and load process.\n",
    "    \n",
    "    Arguments:\n",
    "        cur: the cursor object\n",
    "        conn: object of the connection to the database\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        for query in insert_table_queries:\n",
    "            cur.execute(query)\n",
    "            conn.commit()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "def final_main():\n",
    "    \"\"\"\n",
    "    Description: This main function connects to the database and provides the cursor.\n",
    "                 It also triggers the functions staging_tables and insert_tables.\n",
    "    \n",
    "    Arguments:\n",
    "        None\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('dwh.cfg')\n",
    "\n",
    "        conn = psycopg2.connect(\"host={} dbname={} user={} password={} port={}\".format(*config['CLUSTER'].values()))\n",
    "        cur = conn.cursor()\n",
    "\n",
    "        load_staging_tables(cur, conn)\n",
    "        insert_tables(cur, conn)\n",
    "\n",
    "        conn.close()\n",
    "    except psycopg2.Error as e:\n",
    "        print(e)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bd17945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "syntax error at or near \"arn\"\n",
      "LINE 3:                          IAM_ROLE arn:aws:iam::712001213231:...\n",
      "                                          ^\n",
      "\n",
      "current transaction is aborted, commands ignored until end of transaction block\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b6a600",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
